import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
#Importing the required libraries.

from sklearn.cluster import KMeans  # For clustering
from sklearn.decomposition import PCA  # Linear Dimensionality reduction

df = pd.read_csv("sales_data_sample.csv", encoding='unicode_escape')  # Loading the dataset.
print(df)

# Dropping categorical unnecessary columns along with columns having many null values.
df_drop = ['ADDRESSLINE1', 'ADDRESSLINE2', 'STATUS', 'POSTALCODE', 'CITY', 
           'TERRITORY', 'PHONE', 'STATE', 'CONTACTFIRSTNAME', 'CONTACTLASTNAME', 
           'CUSTOMERNAME', 'ORDERNUMBER']
df = df.drop(df_drop, axis=1)
print(df)

# Checking the categorical columns.
print(df['COUNTRY'].unique())
print(df['PRODUCTLINE'].unique())
print(df['DEALSIZE'].unique())

# Converting the categorical columns to dummy variables.
productline = pd.get_dummies(df['PRODUCTLINE'])
Dealsize = pd.get_dummies(df['DEALSIZE'])
df = pd.concat([df, productline, Dealsize], axis=1)

# Dropping the original categorical columns.
df_drop = ['COUNTRY', 'PRODUCTLINE', 'DEALSIZE']
df = df.drop(df_drop, axis=1)

# Converting 'PRODUCTCODE' to numerical values and dropping 'ORDERDATE'.
df['PRODUCTCODE'] = pd.Categorical(df['PRODUCTCODE']).codes
df.drop('ORDERDATE', axis=1, inplace=True)  # Dropping the Orderdate as Month is already included.
print(df.dtypes)  # Checking all datatypes are numeric.

# Plotting the Elbow Plot to determine the number of clusters.
distortions = []  # Within Cluster Sum of Squares from the centroid
K = range(1, 10)

for k in K:
    kmeanModel = KMeans(n_clusters=k)
    kmeanModel.fit(df)
    distortions.append(kmeanModel.inertia_)  # Appending the inertia to the distortions list

plt.figure(figsize=(16, 8))
plt.plot(K, distortions, 'bx-')
plt.xlabel('k')
plt.ylabel('Distortion')
plt.title('The Elbow Method showing the optimal k')
plt.show()


# From the elbow plot, we choose k=3 for clustering.
X_train = df.values  # Returns a numpy array.
print(X_train.shape)

model = KMeans(n_clusters=3, random_state=2)  # Number of clusters = 3
model = model.fit(X_train)  # Fitting the model
predictions = model.predict(X_train)  # Predicting cluster values (0, 1, or 2)

# Counting the number of samples in each cluster
unique, counts = np.unique(predictions, return_counts=True)
counts = counts.reshape(1, 3)
counts_df = pd.DataFrame(counts, columns=['Cluster1', 'Cluster2', 'Cluster3'])
print(counts_df)


# Applying PCA to reduce dimensions to 2 for visualization.
pca = PCA(n_components=2)
reduced_X = pd.DataFrame(pca.fit_transform(X_train), columns=['PCA1', 'PCA2'])
print(reduced_X)

# Plotting the PCA results.
plt.figure(figsize=(14, 10))
plt.scatter(reduced_X['PCA1'], reduced_X['PCA2'])
plt.title('Scatter Plot of PCA Components')
plt.xlabel('PCA1')
plt.ylabel('PCA2')
plt.show()

# Finding the centroids from the KMeans model.
centroids = model.cluster_centers_

# Transforming the centroids into PCA space.
reduced_centers = pca.transform(centroids)
print(reduced_centers)

# Plotting the data points and centroids.
plt.figure(figsize=(14, 10))
plt.scatter(reduced_X['PCA1'], reduced_X['PCA2'])
plt.scatter(reduced_centers[:, 0], reduced_centers[:, 1], color='black', marker='x', s=300)
plt.title('Cluster Centers in PCA Space')
plt.show()



# Adding the cluster predictions to the PCA DataFrame.
reduced_X['Clusters'] = predictions
reduced_X.head()

# Plotting the clusters with different colors.
plt.figure(figsize=(14, 10))
plt.scatter(reduced_X[reduced_X['Clusters'] == 0]['PCA1'], reduced_X[reduced_X['Clusters'] == 0]['PCA2'], color='slateblue', label='Cluster 0')
plt.scatter(reduced_X[reduced_X['Clusters'] == 1]['PCA1'], reduced_X[reduced_X['Clusters'] == 1]['PCA2'], color='springgreen', label='Cluster 1')
plt.scatter(reduced_X[reduced_X['Clusters'] == 2]['PCA1'], reduced_X[reduced_X['Clusters'] == 2]['PCA2'], color='indigo', label='Cluster 2')

plt.scatter(reduced_centers[:, 0], reduced_centers[:, 1], color='black', marker='x', s=300, label='Centroids')
plt.title('Clusters and Centroids')
plt.xlabel('PCA1')
plt.ylabel('PCA2')
plt.legend()
plt.show()